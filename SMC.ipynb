{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Projet Cassiop√©e </center>\n",
    "\n",
    "##  <center> Sequential Monte Carlo methods </center>\n",
    "\n",
    "State space models are bivariate stichastic procceses $\\{(Y_i,Z_i)\\}_{i \\geq 1}$ where the state sequence $(Z_i)_{i \\geq 1}$ is a Markov chain which is only paritally observed through the sequence $(Y_i)_{i \\geq 1}$.\n",
    "- $(Z_i)_{i \\geq 1}$ is a Markov chain ;\n",
    "- $(Y_i)_{i \\geq 1}$ observations : **Conditionnally on the sequence $(Z_i)_{i\\geq 1}$**, the observations are independent. $\\forall l \\geq 1$, the **conditionnal** distribution of $Y_l$ **given** $(Z_i)_{\\geq 1}$ depends on $Z_l$ only ;\n",
    "\n",
    "### Conditionnally Linear and Gaussian Models (CLGM)\n",
    "##### State equation :  $\\ \\ \\ \\forall i \\geq 2,\\ \\ \\ Z_i=d_{a_i}+T_{a_i}Z_{i-1} +H_{a_i}\\epsilon_i\\ \\ \\ \\ \\ \\ \\ (1)$ \n",
    "\n",
    " where :\n",
    " \n",
    " - $\\epsilon_i \\overset{i.i.d}{\\sim}\\mathcal{N}(0_m, I_m)$ ; \n",
    " \n",
    " - $(a_i)_{i\\geq 1}$, regimes, homogeneous Markov chain $\\in \\{1,\\ldots,J\\}$ with initial distribution $\\pi$ and transition matrix $Q$ ;\n",
    " \n",
    " - $\\forall j \\in \\{1,\\ldots, J\\}$, $H_j \\in S_m^{++}$, $d_j \\in \\mathbb{R}^m$, $T_j \\in S_m^{++}$ ;\n",
    " \n",
    " - $Z_1 \\sim \\mathcal{N}(\\mu_1,\\Sigma_1)$ independent of $(\\epsilon_i)_{i \\geq 2}$\n",
    " \n",
    "##### Observation equation : $\\ \\ \\ \\forall i\\in \\{1,\\ldots,n\\},\\ \\ \\ Y_i=c_{a_i}+B_{a_i}Z_{i} +G_{a_i}\\eta_i\\ \\ \\ \\ \\ \\ \\ (2)$ \n",
    "\n",
    "\n",
    "where :\n",
    "\n",
    "- $\\eta_i$ i.i.d p-dim Gaussian vectors independent of $(\\epsilon_i)_{i\\geq 2}$ and $Z_1$ ;\n",
    "\n",
    "- $G_j \\in S_p^{++}$, $c_j \\in \\mathbb{R}^p$ and $B_j \\in \\mathbb{R}^{p\\times m}$\n",
    "\n",
    "### Rao-Blackwellized smoothing algorithms\n",
    "We define and note, \n",
    "\n",
    "- For a given matrix $M$, $\\ \\ \\ \\ \\bar{M}=MM^T$ ;\n",
    "\n",
    "- If $A\\in S_m^{++}$, $\\forall z \\in \\mathbb{R}^m$ :     $\\ \\ \\ \\ \\|z\\|^2_A:=z^T A^{-1}z$ ;\n",
    "\n",
    "- Probability density of of the conditional distribution of $Z_i$ given $(a_i,z_{i-1})$ : \n",
    "\n",
    "<center> $m(a_i,z_{i-1};z_i)=|2\\pi \\bar{H}_{a_i}|^{-\\frac{1}{2}} \\exp\\{-\\frac{1}{2} \\|z_i-d_{a_i}-T_{a_i}z_{i-1}\\|^2_{\\bar{H}_{a_i}}\\}$ </center>\n",
    "\n",
    "- Probability density of of the conditional distribution of $Y_i$ given $(a_i,z_{i})$ : \n",
    "\n",
    "<center> $g(a_i,z_{i};y_i)=|2\\pi \\bar{G}_{a_i}|^{-\\frac{1}{2}} \\exp\\{-\\frac{1}{2} \\|y_i-c_{a_i}-B_{a_i}z_{i}\\|^2_{\\bar{G}_{a_i}}\\}$ </center>\n",
    "\n",
    "\n",
    "#### Forward Filter (FF)\n",
    "Approximate $p(a_{1:i},z_i|y_{1:i})$ by\n",
    "\n",
    "<center>$p^N(a_{1:i},z_i|y_{1:i})=\\underset{k=1}{\\overset{N}{\\sum}}\\ \\omega^k_ip(z_i|a^k_{1:i},y_{1:i})\\ \\delta_{a^k_{1:i}}(a_{1:i})$</center>\n",
    "\n",
    "where $(a^k_{1:i})_{1\\leq k\\leq N}$ produced sequence of trajectories associated with normalized importance weights $(\\omega^k_{1:i})_{1\\leq k\\leq N}$ and $Z_i|a^k_{1:i}, Y_{1:i} \\sim \\mathcal{N}(\\mu^k_i,P^k_i)$ \n",
    "\n",
    "##### Initialisation :\n",
    "- At time $i$ and $\\forall\\ 1\\leq j \\leq J$ : $\\ \\ \\ \\ \\mu_{1|0}^j=c_j+B_j\\mu_1$ and $P^j_{1|0}=B_j\\Sigma_1B^T+\\bar{G}_j\\ \\ \\ \\ \\ $  see $(2)$\n",
    "\n",
    "- $(a^k_{1})_{1\\leq k\\leq N}$ sampled in $\\{1,\\ldots,N\\}$ (each particle is associated with $\\omega^k_1=\\frac{1}{N}$) with probabilities proportional to \n",
    "<center> $\\pi_jp(a_1=j|y_1)\\propto \\pi_j|P^j_{1|0}|^{-\\frac{1}{2}}\\exp\\{-\\frac{1}{2}(y_1-\\mu_{1|0}^j)^T(P_{1|0}^j)^{-1}(y_1-\\mu_{1|0}^j)\\}$</center>\n",
    "\n",
    "Kalman Filter :\n",
    "- <center> $K_1^k=\\Sigma_1 B_{a_1^k}^T(B_{a_1^k}\\Sigma_1B_{a_1^k}^T+\\bar{G}_{a_1^k})^{-1}\\ \\ ,$</center>\n",
    "\n",
    "\n",
    "- <center> $\\mu_1^k=\\mu_1+ K^k_1(Y_1-c_{a_1^k}-B_{a_1^k}\\mu_1)\\ \\ ,$</center>\n",
    "\n",
    "\n",
    "- <center> $P_1^k=(I_m- K^k_1B_{a_1^k})\\Sigma_1, \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  \\ \\ \\ \\  $</center>\n",
    "\n",
    "##### Iterations :\n",
    "\n",
    "Extend the trajectories $(a^k_{1:i-1})_{1\\leq k \\leq N}$ at time i.\n",
    "\n",
    "We note : $\\gamma_i^{j,k}:=p(y_i|a_i=j,a^k_{1:i-1},y_{1:i-1})Q(a^k_{i-1},j)$\n",
    "\n",
    "Since, $Y_i|a^k_{1:i-1},a_i, Y_{1:i-1} \\sim \\mathcal{N}(c_{a_i}+B_{a_i}\\mu^k_{i|i-1}(a_i), B_{a_i}P^k_{i|i-1}(a_i)B_{a_i}^T+\\bar{G}_{a_i})$\n",
    "\n",
    "Therefore, \n",
    "<center>$\\gamma_i^{j,k}\\propto Q(a^k_{i-1},j)|B_{j}P^k_{i|i-1}B_{j}^T+\\bar{G}_{j}|^{-\\frac{1}{2}} \\exp\\{-\\frac{1}{2}\\|y_i-c_{j}-B_{j}\\mu^{j,k}_{i|i-1}\\|^2_{B_{j}P^k_{i|i-1}B_{j}^T+\\bar{G}_{j}}\\}$ </center>\n",
    "\n",
    "where : \n",
    "\n",
    "- <center>$\\mu^k_{i|i-1}=\\mu^k_{i|i-1}(j)=d_j+T_j\\mu^k_{i-1}\\ \\ \\ \\ \\ \\ \\ $ </center>\n",
    "\n",
    "\n",
    "- <center> $P^k_{i|i-1} = P^k_{i|i-1}(j)=T_j P^k_{i-1} T_j^T +\\bar{H}_j$ </center>\n",
    "\n",
    "\n",
    "$\\forall k \\in \\{1,\\ldots,N\\}$, an ancestral path is chosen with probabilities proportional to $(\\omega^k_{i-1})_{1 \\leq k \\leq N}$. \n",
    "\n",
    "Then, the new regime $a_i^k$ is sampled in $\\{1,\\ldots,J\\}$ with probabilities proportional to $(\\gamma^{j,k}_i)_{1 \\leq j \\leq J}$. \n",
    "\n",
    "Only ancestral paths that have been selected using the imprtance weights $(\\omega^k_{i-1})_{1 \\leq k \\leq N}$ are extended at time $i$. (This is improved by considering all the offsprings of all ancestral trajectories $(a^k_{1:i-1})_{1 \\leq k \\leq N}$. Each ancestral path has $J$ offsprings at time $i$ then, we choose a given number of trajectories at time $i$ among the  $NJ$ possible paths).\n",
    "\n",
    "To obtain the weight associated with each offspring\n",
    "write the following approximation of $p(a_{1:i}|y_{1:i})$ based on the weighted samples at time $i-1$ :\n",
    "\n",
    "<center>$p^N(a_{1:i}|y_{1:i}) \\propto \\underset{k=1}{\\overset{N}{\\sum}}\\underset{j=1}{\\overset{J}{\\sum}}\\omega^k_{i-1} \\gamma^{j,k}_i\\delta_{(a^k_{1:i-1},j)}(a_{1:i}) $</center>\n",
    "\n",
    "\n",
    "Therefore, each ancestral trajectory of the form $(a^k_{1:i-1},j)$,$ 1\\leq k\\leq N$, $1\\leq j \\leq J$ is associated with the normalised weight $\\tilde{\\omega}_i^{j,k} \\propto \\omega_i^{j,k} \\gamma_i^{j,k} $.\n",
    "( We might use **KL-OS** or **CS-OS** to associate a new weight to each of the $NJ$ tajectories, if the new weight is null then the particle can be removed).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regimes(J,P0,Q,n):\n",
    "    # n : number of regimes\n",
    "    # J : integer defining the finite space {1,...,J}, the values of the regimes \n",
    "    # P0 : initial distribution\n",
    "    # Q : transition matrix\n",
    "    \n",
    "    a=np.zeros(n)\n",
    "    j=np.arange(1,J+1)\n",
    "    \n",
    "    '''p=rd.random()\n",
    "    Psum=np.cumsum(P0)\n",
    "    k=0\n",
    "    while p>Psum[k]:\n",
    "        k=k+1\n",
    "    a[0]=k+1\n",
    "    '''\n",
    "    a[0]=np.random.multinomial(1,P0).dot(j)\n",
    "    \n",
    "    '''Qsum=np.cumsum(Q,axis=1)'''\n",
    "    for i in range(1,n):\n",
    "        a[i]=np.random.multinomial(1,Q[int(a[i-1])-1]).dot(j)\n",
    "        \n",
    "        '''p=rd.random()\n",
    "        k=0\n",
    "        while p>Qsum[int(a[i-1])-1][k]:\n",
    "            k=k+1\n",
    "        a[i]=k+1'''\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 3., 1., 1., 1., 3., 3., 3., 3., 3., 3., 3., 2., 1., 1., 1., 1.,\n",
       "       1., 3., 3., 3., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 3., 1., 3., 3., 2., 2., 2., 2., 3., 2., 2., 2., 3.,\n",
       "       1., 1., 1., 1., 1., 1., 3., 2., 2., 2., 2., 2., 2., 2., 2., 2., 3.,\n",
       "       3., 3., 2., 3., 2., 2., 1., 1., 1., 3., 2., 2., 2., 3., 2., 2., 2.,\n",
       "       1., 3., 2., 2., 2., 2., 3., 2., 2., 2., 2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "Q= np.array([[0.6,0.1,0.3],[0.1,0.7,0.2],[0.2,0.3,0.5]])\n",
    "P0=np.array([0.5,0.4,0.1])\n",
    "regimes(3,P0,Q,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_states(d,T,H,mu1,sigma1,regimes):\n",
    "    # d : list of the J m-vectors dj;\n",
    "    # T, H : lists of the J mxm-positive-definite matrices Tj and Hj, T=[T1,T2,...,TJ] ;\n",
    "    # mu1, sigma1 : mean and variance of the m-Gaussian rdvar Z1 ;\n",
    "    # n : number of trajectories ;\n",
    "    \n",
    "    m=np.shape(d[0])[0]\n",
    "    n=np.shape(regimes)[0]\n",
    "    states=[]\n",
    "    states.append(np.random.normal(mu1,sigma1))\n",
    "    for i in range(1,n):\n",
    "        epsilon_i=np.random.normal(np.zeros(m),np.eye(m))\n",
    "        a_i=int(regimes[i])-1 #a confimer pour les indices\n",
    "        states.append(d[a_i]+T[a_i].dot(state[i-1])+H[a_i].dot(epsilon_i))\n",
    "    return states     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_observations(c,B,G,states,regimes,mu,sigma):\n",
    "    # c : list of the J p-vectors cj ;\n",
    "    # B : list of the J pxm-matrices Bj ;\n",
    "    # G : list of the J pxp-positive-definite matrices Gj ;\n",
    "    # mu, sigma : mean and variance of the i.i.d p-Gaussian vectors eta_i ;\n",
    "    \n",
    "    p=np.shape(c[0])[0]\n",
    "    m=np.shape(states[0])[0]\n",
    "    observations=[]\n",
    "    for i in range(n):\n",
    "        eta_i=np.random.normal(mu,sigma)\n",
    "        a_i=int(regimes[i])-1\n",
    "        observations.append(c[a_i]+B[a_i].dot(state[i])+G[a_i].dot(eta_i))\n",
    "    return observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_squared(z,A):\n",
    "    # z is a m vector\n",
    "    # A is a positive-definite matrix\n",
    "    return np.transpose(z).dot(np.linalg.inv(A).dot(z))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar(A):\n",
    "    return A.dot(np.transpose(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_filter(c,d,B,G,T,H,mu1,sigma1,Pi,Y):\n",
    "    # Initialization : i=1\n",
    "    mu_1_0=[]\n",
    "    P_1_0=[]\n",
    "    P_sample=np.zeros(J)\n",
    "    s=0\n",
    "    for j in range(J):\n",
    "        mu_1_0_j=c[j]+B[j].dot(mu1)\n",
    "        mu_1_0.append(mu_1_0_j)\n",
    "        P_1_0_j=B[j].dot(sigma1.dot(np.transpose(B[j])))+bar(G[j])\n",
    "        P_1_0.append(P_1_0_j)\n",
    "        P_sample_j=Pi[j]*((np.linalg.det(P_1_0_j))**(-0.5))*np.exp(-0.5*norm_squared(Y[0]-mu_1_0_j,P_1_0_j))\n",
    "        P_sample[j]=P_sample_j\n",
    "        s+=P_sample_j\n",
    "        \n",
    "    P_sample_norm=P_sample/s\n",
    "    \n",
    "    j=np.arange(1,J+1)\n",
    "    a_1=np.zeros(N)\n",
    "    P_1_1=[]\n",
    "    mu_1_1=[]\n",
    "    (m,p)=np.shape(B[0])\n",
    "    K_1_k=np.zeros((m,p))\n",
    "    mu_1_1_k=np.zeros(m)\n",
    "    P_1_1_k=np.zeros((m,m))\n",
    "    omega_1=(1/N)*np.ones(N)\n",
    "    for k in range(N):\n",
    "        \n",
    "        a_1[k]=int(np.random.multinomial(1,P_sample_norm[k]).dot(j))\n",
    "        \n",
    "        K_1_k=sigma1.dot(np.transpose(B[a_1[k]]).dot(np.linalg.inv(B[a_1[k]].dot(sigma1.dot(np.transpose(B[a_1[k]])))+bar(G[a_1[k]]))))\n",
    "        mu_1_1_k=mu1+K_1_k.dot(Y[0]-c[a_1[k]]-B[a_1[k]].dot(mu1))\n",
    "        mu_1_1.append(mu_1_1_k)\n",
    "        P_1_1_k=(np.eye(m)-K_1_k.dot(B[a_1[k]])).dot(sigma1)\n",
    "        P_1_1.append(P_1_1_k)\n",
    "    P=[]\n",
    "    P.append(P_1_1)\n",
    "    mu=[]\n",
    "    mu.append(mu_1_1)\n",
    "    a=[]\n",
    "    a.append(a_1)\n",
    "    gamma_i=[]\n",
    "    for i in range(1,n):\n",
    "        for k in range(N):\n",
    "            gamma_i_k=np.zeros(J)\n",
    "            a_i_k=np.zeros(N)\n",
    "            S=0\n",
    "            for j in range(J):\n",
    "                mu_pred= d[j]+T[j].dot(mu[i-1][k])\n",
    "                P_pred=T[j].dot(P[i-1][k].dot(T[j].transpose())) + bar(H[j])\n",
    "                gamma_i_k[j]=Q[int(a[i-1][k])-1][j]*(np.linalg.det(B[j].dot(P_pred.dot(\n",
    "                    B[j].transpose)))**(-0.5))*np.exp(-0.5*norm_squared(\n",
    "                    Y[i]-c[j]-B[j].dot(mu_pred),B[j].dot(P_pred.dot(B[j].transpose))+bar(G[j])))\n",
    "                S+=gamma_i_k[j]\n",
    "            \n",
    "            gamma_i_k=gamma_i_k/S\n",
    "            gamma_i.append(gamma_i_k)\n",
    "            a_i_k=np.random.multinomial(1,)    \n",
    "                \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
